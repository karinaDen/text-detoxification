{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example of Delete Basline work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    I'm not gonna have a child... ...with the same...\n",
              "1    They're all laughing at us, so we'll kick your...\n",
              "2      Maine was very short on black people back then.\n",
              "3    So now their spirits are cursed, walking back ...\n",
              "4                 Come on, Cal, leave that shit alone.\n",
              "Name: reference, dtype: object"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# data frame with toxic sentences\n",
        "df = pd.read_csv('../data/interim/filtered.csv')\n",
        "df = df['reference']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['mound of venus', 'asslover', 's&m', 'queaf', 'whitetrash']\n"
          ]
        }
      ],
      "source": [
        "with open('../data/interim/bad_words.txt', 'r') as file:\n",
        "    # Read the contents of the file\n",
        "    bw = file.read().splitlines()\n",
        "\n",
        "print(bw[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "She wanted to tattoo my name on her tit.\n"
          ]
        }
      ],
      "source": [
        "#take random sentence from data frame and dalete all \"bad\" words from here\n",
        "import random\n",
        "\n",
        "example = df[random.randint(0, len(df))]\n",
        "\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "She wanted to tattoo my name on her.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import sys\n",
        "sys.path.insert(0, '../src/models/baseline')\n",
        "\n",
        "from delete_baseline import delete_baseline\n",
        "\n",
        "print(delete_baseline(example, bw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "run python code to delete all \"bad\" words in reference text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-toxic sentences have been written to the output file.\n"
          ]
        }
      ],
      "source": [
        "!python ../src/models/baseline/predict_baseline.py "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate output text using Scoltex metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDVD1Z5TyEhk",
        "outputId": "6461ad46-bef9-42e6-b634-b6cf0a8f8711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating style of predictions\n",
            "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100% 9974/9974 [13:00<00:00, 12.78it/s]\n",
            "Calculating BLEU similarity\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "Calculating similarity by Wieting subword-embedding SIM model\n",
            "100% 9974/9974 [01:23<00:00, 118.97it/s]\n",
            "Calculating CoLA acceptability stats\n",
            "Downloading (…)lve/main/config.json: 100% 628/628 [00:00<00:00, 3.72MB/s]\n",
            "Downloading model.safetensors: 100% 1.42G/1.42G [00:16<00:00, 87.1MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 289/289 [00:00<00:00, 1.33MB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 798k/798k [00:00<00:00, 3.06MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 6.70MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 6.92MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 239/239 [00:00<00:00, 1.72MB/s]\n",
            "100% 9974/9974 [42:27<00:00,  3.92it/s]\n",
            "| Model | ACC | SIM | FL | J | BLEU |\n",
            "\n",
            "| ----- | --- | --- | -- | - | ---- |\n",
            "\n",
            "baseline.txt|0.7739|0.7307|0.7219|0.3861|0.5060|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python ../src/metrics/metrics.py --inputs ../data/interim/translation.txt --preds ../data/interim/baseline.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
