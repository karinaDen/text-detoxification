{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWLY82zSOgiW"
      },
      "source": [
        "# Fine-tuning the T5-small model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbcfy8uuOgiY"
      },
      "source": [
        "## Fine-tuning the model\n",
        "### Run following cells in case if you want to fine-tune the model by yourself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXQxhY97OgiZ"
      },
      "outputs": [],
      "source": [
        "!python ../src/models/T5/T5_model_train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ZTHolXOgib"
      },
      "source": [
        "## Download the weights of the T5-small model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-03T08:09:00.554836Z",
          "iopub.status.busy": "2023-11-03T08:09:00.554151Z",
          "iopub.status.idle": "2023-11-03T08:09:16.147555Z",
          "shell.execute_reply": "2023-11-03T08:09:16.146477Z",
          "shell.execute_reply.started": "2023-11-03T08:09:00.554795Z"
        },
        "trusted": true,
        "id": "ooJFIk9gOgib",
        "outputId": "899df2fd-f526-4a80-cceb-ddd20169b93e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1TS2FeNofbu_bydF3AaxcszcWs6htSk-G\n",
            "From (redirected): https://drive.google.com/uc?id=1TS2FeNofbu_bydF3AaxcszcWs6htSk-G&confirm=t&uuid=e5fbdea2-d79b-4371-a159-0fb6b71084a8\n",
            "To: /home/karinochka/Innopolis/text-detoxification/models/t5-small/best-model.zip\n",
            "100%|████████████████████████████████████████| 225M/225M [00:38<00:00, 5.84MB/s]\n"
          ]
        }
      ],
      "source": [
        "!python ../src/data/load_weights.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoK_z7SBOgic"
      },
      "source": [
        "## Data example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXmB7yldOgid",
        "outputId": "45ee4028-f52f-45ff-e0e3-86eba6c98056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\"Walter put a lot ofgoddamn money in his billfold, that\\'s why.\"', 'Everybody nice and fucking comfy now?', 'I feel like a jackass now.', '\"Get out of here, you vultures!\"', 'He could actually die here.']\n"
          ]
        }
      ],
      "source": [
        "with open('../data/interim/test_reference.txt', 'r') as file:\n",
        "    # Read the contents of the file\n",
        "    test = file.read().splitlines()\n",
        "\n",
        "print(test[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5AmVuVkOgid"
      },
      "source": [
        "## Predicting with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-11-03T08:07:39.250746Z",
          "iopub.status.busy": "2023-11-03T08:07:39.250400Z",
          "iopub.status.idle": "2023-11-03T08:07:41.836443Z",
          "shell.execute_reply": "2023-11-03T08:07:41.835319Z",
          "shell.execute_reply.started": "2023-11-03T08:07:39.250715Z"
        },
        "trusted": true,
        "id": "tj1bhn73Ogid",
        "outputId": "8ab6db22-5602-4a3b-e15a-23739c784a07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-05 22:33:30.830784: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-05 22:33:30.869950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-05 22:33:31.436335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "100%|█████████████████████████████████████| 5267/5267 [1:03:40<00:00,  1.38it/s]\n"
          ]
        }
      ],
      "source": [
        "!python ../src/models/T5/T5_model_predict.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAs9qZ4TOgie"
      },
      "source": [
        "## Manualy testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-03T08:07:44.277690Z",
          "iopub.status.busy": "2023-11-03T08:07:44.277051Z",
          "iopub.status.idle": "2023-11-03T08:09:00.551921Z",
          "shell.execute_reply": "2023-11-03T08:09:00.550946Z",
          "shell.execute_reply.started": "2023-11-03T08:07:44.277655Z"
        },
        "trusted": true,
        "id": "AruH4tuxOgie",
        "outputId": "a41b777e-0e2e-439b-83c8-25c417b2cccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"You don't really fucking care at all, do you?\"\n"
          ]
        }
      ],
      "source": [
        "# take random sentence from test set\n",
        "import random\n",
        "\n",
        "example = random.choice(test)\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq_iV2pFOgie",
        "outputId": "15ba990a-5823-4974-9330-8e070e200173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"you don't care about all, do you?\"\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "sys.path.append('../src/models/T5/')\n",
        "\n",
        "from T5_model_predict import detoxificate, load_model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "model = load_model(\"../models/t5-small/t5-small\")\n",
        "result = detoxificate(model, tokenizer, example)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4GDzPOjOgif"
      },
      "source": [
        "## Evaluate metrics of a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDa3wN-tOgif",
        "outputId": "44a238e3-cd9b-4d47-8100-e66d0cd6a430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating style of predictions\n",
            "Downloading (…)okenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 94.0kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 798k/798k [00:00<00:00, 7.92MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 8.86MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 239/239 [00:00<00:00, 937kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 794/794 [00:00<00:00, 3.02MB/s]\n",
            "Downloading pytorch_model.bin: 100% 501M/501M [00:05<00:00, 94.6MB/s]\n",
            "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100% 165/165 [06:05<00:00,  2.22s/it]\n",
            "Calculating BLEU similarity\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "Calculating similarity by Wieting subword-embedding SIM model\n",
            "100% 165/165 [00:03<00:00, 51.28it/s]\n",
            "Calculating CoLA acceptability stats\n",
            "Downloading (…)lve/main/config.json: 100% 628/628 [00:00<00:00, 2.30MB/s]\n",
            "Downloading model.safetensors: 100% 1.42G/1.42G [00:26<00:00, 53.7MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 289/289 [00:00<00:00, 793kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 798k/798k [00:00<00:00, 7.89MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 32.6MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 26.6MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 239/239 [00:00<00:00, 1.19MB/s]\n",
            "100% 165/165 [21:25<00:00,  7.79s/it]\n",
            "| Model | ACC | SIM | FL | J | BLEU |\n",
            "\n",
            "| ----- | --- | --- | -- | - | ---- |\n",
            "\n",
            "result.txt|0.7993|0.6640|0.7617|0.4180|0.4627|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python text-detoxification/src/metrics/metrics.py --inputs text-detoxification/data/interim/test_translation.txt --preds text-detoxification/data/interim/result.txt"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}